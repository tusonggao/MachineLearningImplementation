{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "参考 https://www.ibm.com/developerworks/community/blogs/jfp/entry/Fast_Computation_of_AUC_ROC_score?lang=en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numba import jit\n",
    "\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit\n",
    "def fast_auc(y_true, y_prob):\n",
    "    y_true = np.asarray(y_true)\n",
    "    y_true = y_true[np.argsort(y_prob)]\n",
    "    nfalse = 0\n",
    "    auc = 0\n",
    "    n = len(y_true)\n",
    "    for i in range(n):\n",
    "        y_i = y_true[i]\n",
    "        nfalse += (1 - y_i)\n",
    "        auc += y_i * nfalse\n",
    "    auc /= (nfalse * (n - nfalse))\n",
    "    return auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面这个cell 展示另一种计算方法 参考 https://github.com/benhamner/Metrics/blob/master/Python/ml_metrics/auc.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tied_rank(x):\n",
    "    \"\"\"\n",
    "    Computes the tied rank of elements in x.\n",
    "    This function computes the tied rank of elements in x.\n",
    "    Parameters\n",
    "    ----------\n",
    "    x : list of numbers, numpy array\n",
    "    Returns\n",
    "    -------\n",
    "    score : list of numbers\n",
    "            The tied rank f each element in x\n",
    "    \"\"\"\n",
    "    sorted_x = sorted(zip(x,range(len(x))))\n",
    "    r = [0 for k in x]\n",
    "    cur_val = sorted_x[0][0]\n",
    "    last_rank = 0\n",
    "    for i in range(len(sorted_x)):\n",
    "        if cur_val != sorted_x[i][0]:\n",
    "            cur_val = sorted_x[i][0]\n",
    "            for j in range(last_rank, i): \n",
    "                r[sorted_x[j][1]] = float(last_rank+1+i)/2.0\n",
    "            last_rank = i\n",
    "        if i==len(sorted_x)-1:\n",
    "            for j in range(last_rank, i+1): \n",
    "                r[sorted_x[j][1]] = float(last_rank+i+2)/2.0\n",
    "    return r\n",
    "\n",
    "def auc_tsg(actual, posterior):\n",
    "    \"\"\"\n",
    "    Computes the area under the receiver-operater characteristic (AUC)\n",
    "    This function computes the AUC error metric for binary classification.\n",
    "    Parameters\n",
    "    ----------\n",
    "    actual : list of binary numbers, numpy array\n",
    "             The ground truth value\n",
    "    posterior : same type as actual\n",
    "                Defines a ranking on the binary numbers, from most likely to\n",
    "                be positive to least likely to be positive.\n",
    "    Returns\n",
    "    -------\n",
    "    score : double\n",
    "            The mean squared error between actual and posterior\n",
    "    \"\"\"\n",
    "    r = tied_rank(posterior)\n",
    "    num_positive = len([0 for x in actual if x==1])\n",
    "    num_negative = len(actual)-num_positive\n",
    "    sum_positive = sum([r[i] for i in range(len(r)) if actual[i]==1])\n",
    "    auc = ((sum_positive - num_positive*(num_positive+1)/2.0) /\n",
    "           (num_negative*num_positive))\n",
    "    return auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_1: 0.4997397474477496\n",
      "auc_2: 0.49973974744774946\n",
      "auc_3: 0.4997397474477496\n"
     ]
    }
   ],
   "source": [
    "y_true = np.random.randint(0,2,1000000)\n",
    "y_pred = np.random.rand(1000000)\n",
    "\n",
    "auc_1 = fast_auc(y_true, y_pred)\n",
    "auc_2 = roc_auc_score(y_true, y_pred)\n",
    "auc_3 = auc_tsg(y_true, y_pred)\n",
    "\n",
    "print('auc_1:', auc_1)\n",
    "print('auc_2:', auc_2)\n",
    "print('auc_3:', auc_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251 ms ± 12.6 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit fast_auc(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "535 ms ± 52.9 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit roc_auc_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fast_auc比roc_auc_score速度快一倍"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.39 s ± 294 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit auc_tsg(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
